---
title: "Ex05 - Model Explainability"
author: "Reto Heller 1910837262"
date: "14. Juni 2020"
urlcolor: cyan
---

```{r options, include = FALSE}
knitr::opts_chunk$set(fig.align = "center")
```

Bitte um Beachtung der [Übungs-Policy](https://weblearn.fh-kufstein.ac.at/mod/page/view.php?id=46374) für genaue Anweisungen und einige Beurteilungsnotizen. Fehler bei der Einhaltung ergeben Punktabzug.

*Bearbeitungszeit*: 6 Std.



---




## Einleitung


2 Classification use case - Titanic data

```{r}
library(pacman)
p_load(tidyverse,
DALEX,
keras,
titanic,
fastDummies,
h2o)
set.seed(123)
```

Um die Anwendung von DALEX auf Klassifizierungsprobleme zu veranschaulichen, werden wir den im titanic-Paket verfügbaren titanic_train-Datensatz verwenden. Unser Ziel ist die Vorhersage der Wahrscheinlichkeit, dass die Person die Katastrophe überlebt, basierend auf ausgewählten Merkmalen wie Kabinenklasse, Geschlecht, Alter, Anzahl der Familienmitglieder auf dem Schiff, Fahrpreis und Einschiffung. 


Zu Beginn werden wir die Daten aufbereiten und bereinigen. Der erste Unterschied zwischen Keras und h2o besteht darin, dass bei Keras Prädiktoren und explained Variable als separate numerische Tensoren angegeben werden müssen. Das bedeutet, dass wir, wenn wir einen Faktor in das Keras-Modell einfügen wollen, ihn zuerst kodieren müssen. Wir werden eine Ein-Hot-Kodierung mit der Funktion dummy_cols aus dem Paket fastDummies durchführen (sowohl für h2o als auch für Keras, so dass Anzahl und Art der Eingaben identisch sind).

Für den Vergleich erstellen wir auch ein drittes Modell - tree-based - verwende dazu zum Beispiel ein XGBoost Modell oder auch "nur" einen Decision Tree.

**Wichtig**: Wir fokussieren uns wirklich auf die Anwendung von Dalex und auch die Interpretation der Outputs. Diese Übung wird *nicht* automatisiert bewertet - es geht vorrangig um die Verknüpfung der Konzepte - auch ein wenig um Grundlagen Neuronaler Netze.

# Daten-Vorbereitung und Cleaning **[3 Punkte]**

Bereiten wir die Daten so auf dass wir die Variablen `Survived, PClass, Sex, Age, Sibsp, Parch, Fare, Embarked` verwenden. Wir konvertieren die "geeigneten" Variablen als Factor - z.B. Survived. Eine neue Variable `Family_members` ergibt sich aus der Summe der Variablen `SibSp und Parch`. Wir verwerfen `NA` und erstellen "Dummy-Cloumns". Zum Schluss verwerfen wir eben die "überflüssigen" Variablen. ("Sex, Embarked, Parch, Sibsp" und Survived wird nicht "dummy coded").

```{r}
titanic_small <- titanic_small <- titanic_train %>%
  select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
  mutate_at(c("Survived", "Sex", "Embarked"), as.factor) %>%
  mutate(Family_members = SibSp + Parch) %>% 
  na.omit() %>%
  dummy_cols() %>%
  select(-Sex, -Embarked, -Survived_0, -Survived_1, -Parch, -SibSp)
print(head(titanic_small))

# Survived = 0 > No, Survived = 1 > Yes, 
# select variables
# convert factors
# drop nas
# dummy code
# drop unnecessary columns, keep Survived as factor
# print the head
```




Für Keras müsssen wir den "XY-Split" machen. Hinweis - Keras benötigt eine Matrix und "Survived" soll numerisch sein.

```{r}
titanic_small_x <- titanic_small %>% select(-Survived) %>% as.matrix()
# Response Variable Survived
titanic_small_y <- titanic_small %>% select(Survived) %>% mutate(Survived = as.numeric(as.character(Survived))) %>% as.matrix()
```

Nun haben wir 10 Inputvariablen (Fare, Age, Pclass, Family Member, Sex, Embarked) und eine Responsevariable (Survived).

# Modelle **[4 Punkte]**


### H2O 
Wir können das MLP-Modell in h2o mit der h2o.deeplearning-Funktion aufbauen. Dazu müssen wir zuerst h2o initialisieren und titanic_small in H2OFrame konvertieren.

Hinweis: H2O benötigt Java auf eurem System, installiert daher 64-bit Java und achtet auf den richtigen "Pfad". Ändert bzw. löscht ggf. die "JAVA_HOME" Variable und seht euch den "PATH" von User und System genau an.

```{r}
h2o.init()
h2o.no_progress()

titanic_h2o <- as.h2o(titanic_small, destination_frame = "titanic_small") # convert to h2o format using "as.h2o"
model_h2o <- h2o.deeplearning(x = 2:11,
                              y = 1,
                              training_frame = "titanic_small",
                              activation = "Rectifier",
                              hidden = c(16, 8), 
                              epochs = 100,
                              rate = 0.01,
                              adaptive_rate = FALSE, 
                              loss = "CrossEntropy")
# deep learning model with "ReLU", two layers with 16 and 8 neurons, 100 epochs, learning rate of 0.01 and force it to use Simple Gradient Descent -> adaptive_rate = FALSE, use the CrossEntropy Loss
```

Was siehst du im Output? Welche "Art" von NN trainieren wir? Convolutional, LSTM? oder wie heisst das noch gleich?

```{r}
model_h2o
```

Das H20 Modell erreicht eine Area Under the Curve von 89,38 %. Zur Berechnung wurden 71.400 Training Samples herangezogen. Es handelt sich um eine binäre Klassifikation, deswegen die Softmax Aktivierungsfunktion beim Output Layer. Die Error Rate liegt bei 137/714. 


### Keras

Ja man kann Keras und tensorflow auch in R verwenden - Hinweis zur Einrichtung - das Paket `tensorflow` hat eine Funktion `install_tensorflow()` dieses verwendet miniconda um eine separate Umgebung für R+Python anzulegen.

Um ein neuronales Netz in Keras aufzubauen, müssen wir Schichten stapeln, im Falle von MLP werden wir layer_dense verwenden. Das Schema folgt `keras_model_sequential() %>% layer_dense() %>% ...`


```{r}
library(keras)
#install_tensorflow()
```

```{r}

library(reticulate)
Sys.setenv(RETICULATE_PYTHON = "/Users/retoheller/opt/anaconda3/bin/python")

#use_python(python = Sys.which("python3"), required = TRUE)
#py_config()
#use_miniconda("/Users/retoheller/Library/r-miniconda")
#se_condaenv(condaenv = "r-nlp", conda = "/Users/retoheller/opt/anaconda3")
model_keras <- keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = c(10)) %>% 
  layer_dense(units = 8, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model_keras %>% compile(
  optimizer = optimizer_sgd(lr = 0.01), # Simple SGD with learning rate 0.01
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)


# compile the model using compile()
# you can get history + nice output using fit()
```

```{r}
history <- model_keras %>% fit(
  titanic_small_x,
  titanic_small_y,
  epochs = 100,
  validation_split = 0.2
)
```


Versuche die 2 Modelle so "ähnlich" wie möglich zu erstellen - sind sie wirklich "gleich?". 

In der History kann man sehr gut erkennen, dass das Modell sehr schnell dazulernt, aber nach etwa 10 Epochen, verbessert sich das Modell nicht mehr signifikant.



- Wie viele us (mikrosekunden) - braucht dein Endgerät pro Sample? Wie würdest du die Leistung "deines Gerätes" einordnen? Hinweis: Wie viele Kerne verwendet Keras - Nur 1 oder mehrere?


Bei mir braucht das Keras Model ca 12ms pro Step. Das H20 Modell hat nur etwa 8ms pro EPoche benötigt.


### Tree (verwende Parsnip)

Wir erstellen noch ein "Tree-basiertes Modell" mit Parsnip. Notwendige Funktionen sind: `boost_tree(), set_engine(), fit()`. Versuche ein "persönliches" Modell zu erstellen, welches sich mit den NNs messen kann.

```{r}
library(tidymodels)

```


```{r}
model_bt <- decision_tree(mode = "classification") %>%
  set_engine("rpart")

model_bt
```
```{r}
model_bt_fitted <- model_bt%>%
  fit(Survived~., data = titanic_small)
```


### Prädiktionen
Wir können nun die Vorhersagen aller Modelle überprüfen. Denken Sie daran, dass h2o und keras unterschiedliche Implementierungen desselben Algorithmus verwenden und dass es eine Menge anderer, oft randomisierter Parameter gibt, wie z.B. die Werte für die Anfangsgewichte. Um genau dieselben Ergebnisse zu erhalten, müssten Sie also alle berücksichtigen.

Wir verwenden unseren Passagier "Henry". Passagier erster Klasse, 8 Jahre alt, allein, 72$ Fahrpreis, männlich. Ging in Cherbourg an Bord.

Was sagen die drei Modelle zu "Henry"?

```{r}

henry <- data.frame(
  Pclass = 1,
  Age = 8,
  Family_members = 0,
  Fare = 72,
  Sex_male = 1,
  Sex_female = 0,
  Embarked_S = 0,
  Embarked_C = 1,
  Embarked_Q = 0,
  Embarked_ = 0
)
```

```{r}
# convert henry for the models
# predict - henry's survival probabilities for each model
h2o.init()
```

```{r}
henry_h2o <- as.h2o(henry, destination_frame = "henry")
```
```{r}
henry_keras <- as.matrix(henry)
predict(model_h2o, henry_h2o) %>% print()
```
```{r}
predict(model_keras, henry_keras) %>% print()
```

```{r}
predict(model_bt_fitted, henry) %>% print()
```

Die beide Neuronalen Netze kommen auf eine sehr ähnliche Überlebenswahrscheinlichkeit bei dem Passagier Henry. Der Tree sagt ebenfalls diesselbe Klasse voraus.

# Die explain() Funktion **[5 Punkte]**
Der erste Schritt bei der Verwendung des DALEX-Pakets besteht darin, das Black-Box-Modell mit Metadaten zu umhüllen, die die Modellschnittstellen vereinheitlichen.

Um einen Explainer zu erstellen, verwenden wir die Funktion `explain()`. Für die mit dem h2o-Paket erstellten Modelle müssen wir eine benutzerdefinierte Vorhersagefunktion bereitstellen, die zwei Argumente benötigt: Modell und neue Daten und einen numerischen Vektor mit Vorhersagen zurückgibt.

```{r}
custom_predict_h2o <- function(model, newdata)  {
  newdata_h2o <- as.h2o(newdata)
  res <- as.data.frame(h2o.predict(model, newdata_h2o))
  return(as.numeric(res$p1))
}
```



Wir verwenden nun den "Explainer" - dieser enhält: `model`, `data`, `y`(numerisch), `predict_function`(unsere custom_predict_h2o), `label="MLP_h2o"`. `colorize=F` (Farben des Outputs funktionieren nur in der Console, (noch) nicht in RMarkdown)

```{r}
explainer_titanic_h2o <- explain(model = model_h2o, data = titanic_small[ , -1], y = as.numeric(as.character(titanic_small$Survived)),
                                 predict_function = custom_predict_h2o, label = "MLP_h2o", colorize = FALSE)
```

```{r}
explainer_titanic_keras <- explain(model = model_keras, data = titanic_small_x, y = as.numeric(titanic_small_y),
                                   predict_function = predict, label = "MLP_keras", colorize = FALSE)
```

```{r}
custom_predict <- function(object, newdata) {pred <- predict(object, newdata)
                                              response <- pred$.pred
                                              return(response)}

explainer_titanic_tree <- explain(model = model_bt_fitted, data = titanic_small[ , -1], y = as.numeric(as.character(titanic_small$Survived)), label = "MLP_bt", colorize = FALSE)
```


Der Output ist "ziemlich verbose" versuche ihn so umfassend wie möglich zu beschreiben.

# Model performance **[5 Punkte]**
Die Funktion `model_performance()` berechnet Vorhersagen und Residuen für Validierungsdatensätze.

```{r}
mp_titanic_h2o <- model_performance(explainer_titanic_h2o)
```

```{r}
mp_titanic_keras <- model_performance(explainer_titanic_keras)
```

```{r}
#explainer_titanic_tree$data <- as.data.frame(explainer_titanic_tree$data)
#explainer_titanic_tree$y <- as.numeric(explainer_titanic_tree$y)
mp_titanic_tree <- model_performance(explainer_titanic_tree)
#mp_titanic_tree# explain
```


Die generische Funktion print() gibt Quantile für Residuen zurück, ebenso Metriken (Achtung bei Klassifikation)

```{r}
print(mp_titanic_h2o)
```
Auch die Kennzahlen für das h2o Modell sind für eine Regression aufbereitet und deswegen auch nicht wirklich aussagekräftig.

```{r}
print(mp_titanic_keras)
```
Der Output vom Keras Modell zeigt die Ergebnisse als Regressionsproblem. Deswegen sind die Kennzahlen auch nicht aussagekräftig.

```{r}
print(mp_titanic_tree)
```

Das Tree Modell erreicht eine Accuracy von ca. 83% und vor allem eine sehr gute Precision mit 93%

Generic function plot() zeigt eine umgekehrte empirische kumulative Verteilungsfunktion für absolute Werte von Residuen. Diagramme können für ein oder mehrere Modelle generiert werden.

```{r}
plot(mp_titanic_h2o, mp_titanic_keras, mp_titanic_tree)
```

Die Plots zeigen, dass das Modell H20 am besten abschneidet vor dem Tree Modell. Das Tensorflow Modell schneidet am schwächsten ab.

In diesem Plots sieht man auch deutlich, dass das Tree Modell keine Nichtlinearität abbilden kann.

```{r}
plot(mp_titanic_h2o, mp_titanic_keras, mp_titanic_tree, geom = "roc")
```


Wir können auch die plot()-Funktion verwenden, um einen alternativen Vergleich von Residuen zu erhalten. Wenn wir den Parameter `geom = "boxplot"` setzen, können wir die Verteilung der Residuen für ausgewählte Modelle vergleichen.


```{r}
plot(mp_titanic_h2o, mp_titanic_keras, mp_titanic_tree, geom = "boxplot")
```


- Versuche zu Interpretieren - woher kommen die Unterschiede, beschreibe auch die "Hickups" von Dalex mit den diversen Paketen. 

Die Unterschiede sind doch recht groß zwischen den 3 Modellen. Vor allem die weite Box des Keras Modell hat mich ein wenig überrascht, da ich dachte es würde besser abschneiden.

# Variable importance **[5 Punkte]**
Mit dem DALEX-Paket sind wir in der Lage, besser zu verstehen, welche Variablen wichtig sind.

Die Bedeutung der agnostischen Modellvariablen wird mit Hilfe von Permutationen berechnet. Wir subtrahieren einfach die für den Validierungsdatensatz berechnete Verlustfunktion mit permutierten Werten für eine einzelne Variable von der für den Validierungsdatensatz berechneten Verlustfunktion.

Diese Methode ist in der Funktion `variable_importance()` implementiert.

```{r warning=FALSE}
vi_titanic_h2o <- variable_importance(explainer_titanic_h2o) # Importance

```

```{r}
vi_titanic_keras <- variable_importance(explainer_titanic_keras)
```

```{r}
vi_titanic_tree <- variable_importance(explainer_titanic_tree)
```


Wir können alle Modelle mit der generischen Funktion plot() vergleichen.

```{r}
plot(vi_titanic_h2o, vi_titanic_keras, vi_titanic_tree)
```

Beim Variable Importance Plot kann mann die Wichtigkeit der einzelnen Variablen beim jeweiligen Modell erkennen. Beim H2O und beim tree Modell sind die Personenklasse und das Geschlecht die wichtigsten Variablen sind. Beim Keras Modell hingegen das Alter und die Fare.

Die Länge des Intervalls korrespondiert mit der Bedeutung der Variablen. Ein längeres Intervall bedeutet einen größeren Verlust, so dass die Variable wichtiger ist.

Zum besseren Vergleich der Modelle können wir die Wichtigkeit der Variablen mit dem `type="difference"` auf 0 setzen.

```{r}
h2o.init()
```

```{r warning=FALSE}
vi_titanic_h2o_dif <- variable_importance(explainer_titanic_h2o, type="difference")
```

```{r}
vi_titanic_keras_dif <- variable_importance(explainer_titanic_keras, type="difference")
```


```{r}
vi_titanic_tree_dif <- variable_importance(explainer_titanic_tree, type="difference")
```


```{r}
plot(vi_titanic_h2o_dif, vi_titanic_keras_dif, vi_titanic_tree_dif)
```

# Variable response
Die in diesem Abschnitt vorgestellten "Explainer" dienen dem besseren Verständnis der Beziehung zwischen einer Variablen und dem Modell-Output.

Weitere Einzelheiten zu den in diesem Abschnitt beschriebenen Methoden finden Sie im Abschnitt Variable Antwort in den DALEX-Dokumenten.

## 7.1 Partial Dependence Plot **[3 Punkte]**
Partial Dependence Plots (PDP) sind eine der beliebtesten Methoden zur Untersuchung der Beziehung zwischen einer kontinuierlichen Variablen und dem Modellergebnis.

Die Funktion `variable_profile()` (ältere Versionen mit variable_response) mit dem Parametertyp = "pdp" ruft die Funktion `pdp::partial()` auf, um die PDP-Antwort zu berechnen. Es gibt mehrere Varianten der `variable_*()` Funktionen für PDP und ALE. Versuche mehrere

```{r}
vr_age_h2o_pdp  <- variable_profile(explainer_titanic_h2o, variable =  "Age", type = "partial" )
vr_age_keras_pdp  <- variable_profile(explainer_titanic_keras, variable =  "Age", type = "partial")
vr_age_tree_pdp <- variable_profile(explainer_titanic_tree, variable =  "Age", type = "partial")
```

```{r}
plot(vr_age_h2o_pdp)
```


```{r}
plot(vr_age_keras_pdp)
```


```{r}
plot(vr_age_tree_pdp)
```

Wie interpretierst du die Response?  Versuche Verschiedene Arten zu vergleichen, was fällt auf?

Das Keras Modell verhält sich deutlich anders als die anderen beiden Modelle. Beim Tree Modell sinkt die Vorhersage nach einem Alter von größer als 20 nicht mehr. Beim H2o Modell hingegen sinkt die Überlebenswahrscheinlichkeit durchegehend mit zunehmenden Alter. Beim Keras Modell liegt die Vorhersage des Alters immer bei ca. 0,5 egal wie alt der Passagier ist.
Das Tree Modell ist dieser Hinsicht sogar dem H20 Modell ähnlicher als das Keras Modell.


Wie verhalten sich die einzelnen Modelle (2 NNs zueinander), Tree vs. die anderen. Interpretiere die Effekte, Ursachen und Begründe die Darstellung.


## 7.2 Acumulated Local Effects plot **[3 Punkte]**
Der ALE-Plot (Acumulated Local Effects) ist die Erweiterung des PDP, der für hochkorrelierte Variablen besser geeignet ist.

Die Funktion `variable_effect_accumulated_dependency()`  ruft die Funktion ALEPlot::ALEPlot() auf, um die ALE-Kurve für die Variable Alter zu berechnen.

```{r}
vr_age_h2o <-variable_effect_accumulated_dependency(explainer_titanic_h2o, variable =  "Age") # your variable accumulated local effect
vr_age_keras <- variable_effect_accumulated_dependency(explainer_titanic_keras, variable =  "Age") # your variable accumulated local effect
vr_age_tree <- variable_effect_accumulated_dependency(explainer_titanic_tree, variable =  "Age")
# your responses
```

```{r}
plot(vr_age_h2o, vr_age_keras, vr_age_tree)
```


Beim akkumulierten Vraiable Importance Plot sieht man es auch noch mal sehr gut, wie sich die Variable Alter bei den verschiedenen Modellen auswirkt. Beim Keras Modell hat das Alter nur sehr geinger Auswirkungen auf die Vorhersage. Beim Tree Modell wird ist der negative Einfluss maximal 0,5, aber dies bereits ab einem Alter von ca. 20 Jahren. Und wie bereits oben beschrieben hat das zunehmende Alter beim h2o Modell den größten Einfluss.

## 8 Prediction understanding **[2 Punkte]**
Die Funktion `variable_attribution()` ist ein Wrapper um das Breakdown-Paket. Die Modellvorhersage wird mit Breakdown-Plots visualisiert, die den Beitrag jeder im Modell vorhandenen Variablen zeigen. Die Funktion `prediction_breakdown()` erzeugt Variablenattribute für die ausgewählte Vorhersage. Die generische Funktion plot() zeigt diese Zuordnungen.

```{r warning=FALSE}
breakdown_h2o <- variable_attribution(explainer_titanic_h2o,
                 new_observation = henry,
                 type = "break_down")
#breakdown_keras <- variable_attribution(explainer_titanic_keras,
                 #new_observation = henry,
                 #type = "break_down_interactions")
breakdown_tree <- variable_attribution(explainer_titanic_tree,
                 new_observation = henry,
                 type = "break_down")
```
Beim H2o Modell hat die Fare von 72 und die Tatsache das Henry keine Familienmitglieder mit an Board hatte den stärksten negativen Einfluss. auf die Prediction. Die Intercept liegt bei 0,372, somit is es grundsätzlich etwas wahrscheinlicher, dass man stirbt als dass man überlebt. Positiv bei diesem Modell wirkt sich hingegen aus, dass er in erster Klasse gereist ist und er erst 8 Jahre alt war.
```{r}
plot(breakdown_h2o)
```

Beim Tree Modell hingegen ist die Intercept leicht höher mit 0,4. Hier wirkt es sich zum Beispiel negativ aus, dass er männlich ist und erst 8 Jahre alt. Viele Variablen haben aber beim Tree Modell gar keinen Einfluss auf die Vorhersage.
```{r}
plot(breakdown_tree)
```


Wiederum - was ist auffällig für unser Subjekt?

(Optional: Findest du auffällige Interaktionen? SHAP Values?)

Leider konnte ich diesen Plot mit dem Keras Modell nicht ausführen, obwohl mir der Code eigentlich richtig erscheint. Ich habe Ihn deswegen auskommentiert.

```{r warning=FALSE}
shap_h20 <- variable_attribution(explainer_titanic_h2o, 
                                   henry, 
                                   type = "shap",
                                   B = 25)

#shap_keras <- variable_attribution(explainer_titanic_keras, 
                                   #henry, 
                                   ##type = "shap",
                                   #B = 25)

shap_tree <- variable_attribution(explainer_titanic_tree, 
                                   henry, 
                                   type = "shap",
                                   B = 25)
```


```{r}
plot(shap_h20)
```


```{r}
plot(shap_tree)
```

Die beiden Shap Value Plots zeigen nochmal welche Variablen bei welchem Modell einen positven oder negativen Einfluss auf die Vorhersage haben.

Persönliches Fazit:

Die DALEX Library ist an sich echt cool und einfach anzuwenden. Das Tutorial von Hr. Bieczek ist auch wirklich gut und hat mir sehr geholfen. Aber für dieses Übungsblatt bin ich leider knapp 10h vor dem Rechner gesessen.
